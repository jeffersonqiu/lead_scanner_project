{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Project Setup and Core Navigation",
        "description": "Initialize the React Native project with TypeScript, set up the basic navigation structure, and implement camera permission handling.",
        "details": "Establish the foundational React Native project using the TypeScript template. Implement a basic navigation stack for key screens like Camera and Contact Library. Integrate permission handling for the camera and storage, ensuring it works on both iOS and Android.",
        "testStrategy": "Verify that the project builds and runs on both iOS and Android simulators/devices. Confirm that the camera permission prompt appears on first launch and that basic navigation between placeholder screens works as expected.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize React Native Project with TypeScript Template",
            "description": "Create the foundational React Native project using the official TypeScript template and configure basic project settings.",
            "dependencies": [],
            "details": "Use the React Native CLI command `npx react-native init MyApp --template react-native-template-typescript` to generate the project. Set up the application name, bundle identifier, and ensure basic environment configurations (e.g., `.env` files) are in place.",
            "status": "done",
            "testStrategy": "Verify that the new project builds and runs successfully on both an iOS simulator and an Android emulator without any compilation or runtime errors."
          },
          {
            "id": 2,
            "title": "Install and Configure React Navigation",
            "description": "Integrate the React Navigation library and its core dependencies to enable screen-based navigation within the application.",
            "dependencies": [],
            "details": "Add `@react-navigation/native` and `@react-navigation/native-stack` to the project. Install required peer dependencies like `react-native-screens` and `react-native-safe-area-context`. Perform the necessary native setup, including running `pod install` for iOS and updating `MainActivity.java` for Android.",
            "status": "done",
            "testStrategy": "Confirm that the project continues to build and run on both platforms after adding the navigation dependencies and applying native code modifications."
          },
          {
            "id": 3,
            "title": "Implement Navigation Stack with Placeholder Screens",
            "description": "Create placeholder components for the 'Camera' and 'Contact Library' screens and set up a stack navigator to manage transitions between them.",
            "dependencies": [],
            "details": "Develop two basic functional components, `CameraScreen.tsx` and `ContactLibraryScreen.tsx`, each displaying its name. In `App.tsx`, wrap the application in a `NavigationContainer` and configure a `createNativeStackNavigator` with these two screens as routes. Define the initial route.",
            "status": "done",
            "testStrategy": "Run the app and verify the initial screen appears. Add a temporary button to navigate from the initial screen to the second screen and confirm the transition works as expected on both iOS and Android."
          },
          {
            "id": 4,
            "title": "Integrate and Configure Permission Handling Library",
            "description": "Install and set up the `react-native-permissions` library to handle runtime permission requests for camera and storage access.",
            "dependencies": [],
            "details": "Add the `react-native-permissions` package to the project. Configure platform-specific settings by adding usage descriptions (e.g., `NSCameraUsageDescription`) to `Info.plist` for iOS and declaring permissions (e.g., `android.permission.CAMERA`) in `AndroidManifest.xml` for Android.",
            "status": "done",
            "testStrategy": "Rebuild the project on both iOS and Android to ensure it compiles successfully with the new library and native configuration changes. No functional test is required at this stage."
          },
          {
            "id": 5,
            "title": "Implement Camera Permission Request Logic",
            "description": "Develop the logic within the Camera screen to check for and request camera permission from the user upon screen load.",
            "dependencies": [],
            "details": "In the `CameraScreen.tsx` component, use a `useEffect` hook to call the `react-native-permissions` API to check the current camera permission status. If permission is not already granted, trigger the `request` function to show the native OS prompt. The UI should reflect the permission status (e.g., show a 'Grant Permission' button if denied).",
            "status": "done",
            "testStrategy": "On first launch, navigate to the Camera screen and verify that the native permission prompt appears. Test the app's behavior for both 'Allow' and 'Deny' scenarios. Confirm the prompt does not reappear on subsequent visits if permission was granted."
          }
        ]
      },
      {
        "id": 2,
        "title": "Implement Camera Capture with Bounding Box Guidance",
        "description": "Integrate `react-native-vision-camera` to display a live camera feed and overlay a real-time bounding box to guide the user for optimal card capture.",
        "details": "Use `react-native-vision-camera` for a high-performance camera interface. Implement a frame processor to detect rectangular shapes or text regions in real-time and render an overlay to guide the user. Add a capture button to take a high-resolution photo.",
        "testStrategy": "Manually test the camera view on physical devices. Confirm the camera feed is smooth and the bounding box overlay appears and adjusts in real-time. Verify that capturing an image saves it correctly to a temporary location.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "To Do",
        "subtasks": [
          {
            "id": 1,
            "title": "Setup `react-native-vision-camera` and Display Live Feed",
            "description": "Install and configure the `react-native-vision-camera` library, handle necessary camera permissions for iOS and Android, and implement a basic component to display a full-screen live camera feed.",
            "dependencies": [],
            "details": "Follow the official installation guide for `react-native-vision-camera`, including adding required permissions to AndroidManifest.xml and Info.plist. Implement permission requests using the library's API. Create a React component that renders the `<Camera>` element, ensuring it is active and correctly configured to show the back camera feed.",
            "status": "done",
            "testStrategy": "Run the app on physical iOS and Android devices. Verify the permission prompt appears on first launch. After granting permission, confirm that a smooth, full-screen, and correctly oriented camera feed is displayed."
          },
          {
            "id": 2,
            "title": "Implement Frame Processor for Real-Time Text Detection",
            "description": "Integrate a frame processor to analyze the camera feed in real-time. Use a text recognition plugin, like ML Kit, to detect the bounding boxes of text blocks on the feed.",
            "dependencies": [
              "2.1"
            ],
            "details": "Add the `frameProcessor` prop to the `<Camera>` component. Use a worklet function for the processor. Integrate a library like `vision-camera-ocr` or `react-native-mlkit-text-recognition` to process the `Frame` object. The processor should return an array of detected text blocks with their bounding box coordinates.",
            "status": "pending",
            "testStrategy": "Point the camera at a business card or any document with text. Log the output of the frame processor to the console. Confirm that arrays of text blocks and their corresponding bounding box coordinates are being logged in real-time."
          },
          {
            "id": 3,
            "title": "Render Dynamic Bounding Box Overlay",
            "description": "Develop a UI component that takes the coordinates from the frame processor and renders a bounding box overlay on top of the camera view. The overlay should guide the user by highlighting the detected card.",
            "dependencies": [
              "2.2"
            ],
            "details": "Use a state variable to hold the bounding box data from the frame processor. Render an absolutely positioned `<View>` on top of the camera preview. Bind its style (top, left, width, height) to the state. Implement logic to transform the coordinates from the frame's resolution to the screen's resolution and orientation.",
            "status": "pending",
            "testStrategy": "On a physical device, point the camera at a business card. Verify that a bounding box appears around the card's text. Move the camera and the card to confirm the box adjusts its position and size smoothly and accurately in real-time."
          },
          {
            "id": 4,
            "title": "Add Capture Button and Photo-Taking Logic",
            "description": "Implement a UI button that, when pressed, triggers the `takePhoto` method of the `react-native-vision-camera` instance to capture a high-resolution image of the current view.",
            "dependencies": [
              "2.1"
            ],
            "details": "Create a `useRef` for the `<Camera>` component to access its methods. Add a `<TouchableOpacity>` or a custom button component to the UI, overlaid on the camera view. The button's `onPress` handler should call `cameraRef.current.takePhoto()` with options set for high resolution and quality.",
            "status": "pending",
            "testStrategy": "Press the capture button while the camera view is active. Confirm the app does not crash and that the `takePhoto` promise resolves successfully. Log the path of the saved photo to verify it was created in the device's temporary directory."
          },
          {
            "id": 5,
            "title": "Handle and Store Captured Image Path",
            "description": "After a photo is successfully captured, process the result by storing the image file's path. This prepares the image to be passed to the next step in the workflow, such as OCR processing.",
            "dependencies": [
              "2.4"
            ],
            "details": "In the `onPress` handler for the capture button, await the result from `takePhoto()`. The result object contains the `path` to the captured image. Store this path in a state variable or pass it as a parameter using a navigation library to a confirmation or processing screen.",
            "status": "pending",
            "testStrategy": "After capturing an image, verify that the application logic correctly receives the image path. If navigating to a new screen, confirm the path is passed correctly. Manually check the device's file system (if possible) or use a file system library to confirm the image file exists at the specified path."
          }
        ]
      },
      {
        "id": 3,
        "title": "Integrate On-Device OCR with Google ML Kit",
        "description": "Process captured business card images using Google ML Kit Text Recognition v2 to extract raw text blocks locally on the device.",
        "details": "Set up the Google ML Kit Text Recognition v2 module for both iOS and Android. Create a processing service that takes a captured image URI and returns the extracted raw text. Ensure this process is fully on-device and does not require an internet connection.",
        "testStrategy": "Create unit tests for the OCR service using a set of sample business card images. Verify that the extracted text is accurate (>90% on standard cards) and that the processing time is under 2.5 seconds on a mid-range device.",
        "priority": "high",
        "dependencies": [
          2
        ],
        "status": "To Do",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Implement AI-Powered Field Parsing",
        "description": "Send the raw OCR text to the OpenAI API to parse it into a structured contact JSON object, mapping text to fields like name, company, and email.",
        "details": "Develop a client to securely communicate with the OpenAI API. Construct a prompt that instructs the model to convert unstructured text blocks into a JSON object conforming to the `Contact` data model. Implement error handling for API failures and malformed responses.",
        "testStrategy": "Write unit tests for the parsing service with various OCR text samples. Verify that the service correctly parses standard contact information and handles edge cases like missing fields or unusual formatting. Mock the API for testing.",
        "priority": "high",
        "dependencies": [
          3
        ],
        "status": "To Do",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Build Contact Review and Edit Screen",
        "description": "Create a user interface for users to review the AI-parsed contact information, manually edit any fields, and save the final contact to the library.",
        "details": "Design a form that is pre-populated with the data from the AI parsing step. Each field (name, title, phone, etc.) should be editable. Include 'Save' and 'Cancel' actions. Upon saving, the contact data should be passed to the local storage service.",
        "testStrategy": "Perform UI testing to ensure that data is correctly displayed in the form fields. Verify that edits are captured and that the 'Save' action triggers the storage logic with the correct data payload.",
        "priority": "high",
        "dependencies": [
          4
        ],
        "status": "To Do",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Implement Local Contact Storage and Management",
        "description": "Set up a local database using MMKV or AsyncStorage to perform CRUD (Create, Read, Update, Delete) operations for contacts.",
        "details": "Define the final `Contact` data model in TypeScript. Implement a data layer with functions to save, retrieve a list of, update, and delete contact records. Use a performant key-value store like MMKV for fast access.",
        "testStrategy": "Write unit tests for all CRUD operations. Verify that data persists correctly after the app is closed and reopened. Test performance with a large number of contacts (e.g., 1000+).",
        "priority": "medium",
        "dependencies": [
          5
        ],
        "status": "To Do",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Develop Contact Library UI with Search and Tagging",
        "description": "Create the main library screen to display a list of saved contacts, with functionality for searching, filtering, and applying tags.",
        "details": "Build a virtualized list (e.g., FlashList) to display all saved contacts. Implement a search bar that filters the list in real-time based on contact name, company, etc. Add UI for creating tags and applying them to contacts, and filtering the list by one or more tags.",
        "testStrategy": "Manually test the UI. Verify that the contact list scrolls smoothly. Test the search functionality with various queries. Test adding, removing, and filtering by tags on single and multiple contacts.",
        "priority": "medium",
        "dependencies": [
          6
        ],
        "status": "To Do",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Implement Bulk Export to CSV and vCard",
        "description": "Allow users to select multiple contacts from the library and export them as a single CSV or vCard (.vcf) file using the native share sheet.",
        "details": "Add a multi-select mode to the contact library list. Implement logic to generate vCard 4.0 and CSV formatted strings from the selected contact data. Integrate with the native Share API to allow users to save the file or send it to another app.",
        "testStrategy": "Select a batch of 10+ contacts and trigger the export for both CSV and vCard formats. Open the exported files in a compatible application (e.g., Excel, Google Contacts) and verify that all data is present and correctly formatted.",
        "priority": "medium",
        "dependencies": [
          7
        ],
        "status": "To Do",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Implement Sync to Native Device Contacts",
        "description": "Enable users to select one or more contacts from the app library and save them to the device's native contacts application.",
        "details": "Integrate a library like `react-native-contacts` to interact with the native contacts API. Implement the logic to map the app's contact model to the native contact structure. Handle permissions and provide user feedback on success or failure.",
        "testStrategy": "In the multi-select mode, choose several contacts and use the 'Sync to Native' feature. Check the native iOS/Android contacts app to confirm that the new contacts were added correctly with all relevant fields populated.",
        "priority": "low",
        "dependencies": [
          7
        ],
        "status": "To Do",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Enhance Accessibility and Optimize Performance",
        "description": "Improve app accessibility by adding support for VoiceOver/TalkBack and conduct performance profiling and optimization for a production-ready experience.",
        "details": "Review all UI components and add `accessible`, `accessibilityLabel`, and other relevant props for screen readers. Use profiling tools (e.g., Flipper, Xcode Instruments) to identify and fix performance bottlenecks in rendering, processing, and memory usage.",
        "testStrategy": "Enable VoiceOver (iOS) and TalkBack (Android) and navigate through the entire app to ensure all elements are properly labeled and usable. Measure app launch time, memory usage, and OCR processing speed to ensure they meet the defined performance requirements.",
        "priority": "low",
        "dependencies": [
          8,
          9
        ],
        "status": "To Do",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Redesign Camera UI for Improved Layout and Cohesion",
        "description": "Revamped the camera screen's UI with a modern, cohesive layout. The update improves the spacing and visual integration of the capture button, flash controls, and a new settings button, creating a more professional and balanced user experience.",
        "status": "done",
        "dependencies": [
          2
        ],
        "priority": "medium",
        "details": "The UI redesign is complete. Key changes include: 1. Reduced the vertical spacing between the bottom controls and the main tab bar to 90px for a tighter layout. 2. Modernized the flash button with a glassmorphism effect. 3. Redesigned the capture button with improved shadows and contrast for better prominence. 4. Added a new settings button on the right side of the control bar to balance the flash button. 5. Improved the styling of the instruction text overlay with better borders and spacing.",
        "testStrategy": "1. Visually inspect the new camera UI on multiple physical iOS and Android devices with different screen sizes (e.g., iPhone SE, iPhone Pro Max, small/large Android phones) to confirm layout integrity and responsiveness. 2. Verify that the capture button, flash toggle, and new settings button are all fully functional and easily tappable. 3. Confirm that the new control layout does not obscure the camera's bounding box guidance during card scanning. 4. Perform an accessibility check using VoiceOver/TalkBack to ensure all new and rearranged UI elements are properly labeled and navigable.",
        "subtasks": [
          {
            "id": 1,
            "title": "",
            "description": "Reduce spacing between controls and tab bar to 90px.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "",
            "description": "Modernize flash button with a glassmorphism effect.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "",
            "description": "Redesign capture button with improved shadows and contrast.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "",
            "description": "Add a balanced settings button to the control bar.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "",
            "description": "Improve styling for the instruction text overlay.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 12,
        "title": "Implement Modern Camera UI Inspired by Mobbin Design Patterns",
        "description": "Redesign the camera interface to align with modern mobile UI patterns, featuring a professional layout with improved controls, a dual-ring capture button, and refined visual elements for a polished user experience.",
        "details": "Implement a complete visual overhaul of the camera screen based on Mobbin design inspirations. Key implementation points include: 1) Top Controls: A translucent top bar with a close ('X') icon on the left and a flash toggle icon on the right. 2) Bottom Controls: A bottom bar containing a gallery preview icon on the left, a settings (cog) icon on the right, and the main capture button in the center. 3) Capture Button: Create a dual-ring capture button; a larger, semi-transparent outer ring for visual presence and a smaller, solid inner circle for the touch target. 4) Bounding Box: Restyle the existing bounding box from Task 2 with rounded corners, a subtle outer glow, and increased line weight for better visibility without being distracting. 5) Spacing & Hierarchy: Ensure all elements are aligned to a grid with consistent spacing and padding to establish a clear visual hierarchy and a clean, professional aesthetic.",
        "testStrategy": "1. Perform visual regression testing on multiple iOS and Android devices with varying screen sizes and aspect ratios to ensure layout integrity. 2. Verify the functionality of all interactive elements: close button navigates back, flash toggle cycles states (auto/on/off), gallery icon navigates to the contact library, and settings icon opens the settings view. 3. Confirm the dual-ring capture button correctly triggers the photo capture action. 4. Visually inspect the redesigned bounding box to ensure the new styling (rounded corners, glow) is applied correctly. 5. Compare the final implementation against design mockups or Mobbin reference patterns to ensure aesthetic goals are met.",
        "status": "done",
        "dependencies": [
          2
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 13,
        "title": "Implement Expensify-Inspired Camera UI with Mode Selection",
        "description": "Redesign the camera screen to mirror the Expensify UI, featuring a clean navigation header, a mode selection bar for Manual/Scan/Gallery, and a well-spaced bottom control bar.",
        "details": "1. **Navigation Header:** Implement a fixed top header component. On the left, add a back button (chevron icon) that navigates to the previous screen. In the center, display the static title 'Add Expense'. The header should have a solid background and be separate from the camera view.\n2. **Mode Selection Bar:** Below the header, create a segmented control with three options: 'Manual', 'Scan', and 'Gallery'. 'Scan' should be the default selected mode. The active mode must be visually distinct. Tapping 'Scan' shows the camera, while 'Gallery' should trigger the device's image picker.\n3. **Bottom Control Bar:** Implement a bottom-aligned container with professional spacing. On the left, place an icon button to open the device's photo gallery. In the center, add a large, circular, solid green capture button as the primary action. On the right, include an icon button for flash control that cycles through modes (auto, on, off).\n4. **Layout & Styling:** Ensure all elements are properly spaced with no overlaps, creating a clean, modern aesthetic. The layout must be responsive and adapt to various screen sizes. This implementation will replace the UI from previous camera redesign tasks (Task 11, 12).",
        "testStrategy": "1. **Component Verification:** Confirm the navigation header is present with a functional back button and correct title. Verify the mode selection bar displays all three options with 'Scan' as the default. Check that the bottom control bar contains the gallery icon, green capture button, and flash icon in the correct positions.\n2. **Functional Testing:** Tap the back button and confirm it dismisses the camera view. Tap each mode in the selection bar and verify the UI state changes correctly; tapping 'Gallery' must launch the system image picker. Tap the flash icon and confirm it cycles through its states and updates the icon. Tap the green capture button and verify it triggers the image capture function.\n3. **Visual & Layout Testing:** Perform visual checks on multiple iOS and Android devices with different screen sizes (e.g., iPhone SE, iPhone Pro Max) to ensure consistent spacing, alignment, and no element overlaps or clipping.",
        "status": "done",
        "dependencies": [
          2
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "Implement App-Wide UI Consistency and Design System",
        "description": "Resolve UI inconsistencies across the application by establishing and applying a unified, Expensify-inspired design system, including a redesigned tab bar, a consistent color scheme, and standardized element styling.",
        "details": "1. **Global Design System:** Create a central theme file (e.g., `theme.ts`) that exports design tokens for colors (primary, secondary, text, background, error), typography (font families, sizes, weights), spacing units (based on a 4px or 8px grid), and border-radius values. This system should be based on the Expensify-inspired aesthetic from Task #13.\n2. **Tab Bar Redesign:** Implement a new custom `Scan/Contacts` tab bar component. It must match the Expensify design language, featuring clean lines, specific iconography, and clear active/inactive state styling that is cohesive with the camera screen's mode selector.\n3. **Camera Screen Fix:** On the camera screen, adjust the CSS for the instruction text overlay. Increase its `bottom` or set a `top` value to position it higher on the screen, ensuring it never overlaps with the capture button or bottom controls on any device aspect ratio.\n4. **Component Refactoring:** Audit and refactor all major UI components across the app (Camera, Contact Library, etc.) to consume values from the new global theme file. This ensures all buttons, headers, list items, and input fields adhere to the same design language with proper spacing and modern aesthetics.",
        "testStrategy": "1. **Visual Regression Testing:** Perform a visual review on multiple iOS and Android devices with different screen sizes. Compare the Camera screen and the Contact Library screen to ensure they share a consistent visual identity (colors, fonts, component styles).\n2. **Camera UI Verification:** Open the camera screen and confirm the instruction text is positioned correctly above the capture button and does not overlap on small screens (e.g., iPhone SE).\n3. **Tab Bar Functionality:** Verify the redesigned `Scan/Contacts` tab bar is visually aligned with the Expensify design. Test navigation between tabs and confirm that active/inactive states are styled correctly.\n4. **Design System Audit:** Inspect individual components (buttons, text inputs, headers) on all available screens. Confirm they use the color, typography, and spacing values defined in the central theme file.",
        "status": "done",
        "dependencies": [
          7,
          13
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "Simplify Camera UI for Focused Scanning Experience",
        "description": "Refactor the camera UI to create a cleaner, more focused scanning experience by removing the mode selection bar and relocating secondary controls to the top navigation.",
        "details": "1. **Remove Mode Selection Bar:** Completely remove the 'Manual'/'Scan'/'Gallery' segmented control component introduced in Task #13. The camera screen will now default to and exclusively use the scanning functionality. 2. **Refactor Top Navigation:** Implement a clean top navigation bar. Position a gallery icon button on the left and a flash toggle icon button on the right. Ensure a back/close button is also present for navigation. 3. **Simplify Bottom Controls:** Remove all controls from the bottom bar except for the main capture button. This button should remain centered and styled according to the design system from Task #14. 4. **Layout Readjustment:** Adjust the main camera view to occupy the space previously used by the mode selection bar, creating a larger, more immersive preview. Re-evaluate and adjust the vertical spacing of the bottom capture button for optimal ergonomics.",
        "testStrategy": "1. **UI Verification:** On multiple iOS and Android devices with varying screen sizes, confirm that the mode selection bar is no longer visible. Verify the top navigation bar correctly displays the gallery and flash buttons. Ensure the bottom control area contains only the centered capture button. 2. **Functional Testing:** Tap the gallery button and confirm it navigates to the correct screen. Tap the flash button and verify it cycles through flash states (auto/on/off) and that the camera flash works correctly on capture. Confirm the capture button successfully takes a photo. 3. **Regression Testing:** Ensure that the core camera preview and the bounding box guidance from Task #2 remain fully functional and are not negatively impacted by the layout changes.",
        "status": "done",
        "dependencies": [
          14
        ],
        "priority": "medium",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-08-31T09:45:14.566Z",
      "updated": "2025-08-31T10:54:32.587Z",
      "description": "Tasks for master context"
    }
  }
}